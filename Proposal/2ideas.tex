\section{Main Ideas}
The main focus of our work is to explore what kind of value we can extract out of the ORCAS dataset with regards to using it as distant supervision data. We believe that if our efforts are successful this method can be explored for low resource languages.
\subsection{Dataset Mining}
The focus of our work is to start with general exploration and processing of the ORCAS dataset. We will explore the application of traditional data mining algorithms to explore what signals we can extract. We seek to create a set of signals which we can be used in our downstream experiments to prove or disprove our hypothesis. Some of the methods we plan to explore include: phrase based clustering, click based query clustering, n-gram association analysis, etc.
\subsection{Query Synonym Prediction}
Using the ORCAS dataset, we formulate the query synonym prediction task as a task where the goal is to identifying the word synonyms in queries. These synonyms can then be used to identify similar queries efficiently. //
In this work, we intend to use contextual and non contextual word representations to explore how these methods can represent n-gram and query similarity, and leverage them to build our own knowledge base of query synonyms. We plan to evaluate our approach by predicting the degree of connection between queries (measured by proximity in click graph) and between n-gram terms. Another way to evaluate our mined synonyms would be to compare them against those from English dictionaries such as Merriam-Webster dictionary. We also plan to perform a qualitative evaluation by getting a small portion of the generated query synonyms analyzed by human evaluators. 

To further explore how such user logs can help learn signals about query similarities, we plan to leverage the query co-clicks from ORCAS in a transfer learning setting for a related task of Quora duplicate question detection\footnote{\href{https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs}{Quora Duplicate Question Detection}}. We will investigate how well a model trained on the query co-clicks from ORCAS performs on the Quora dataset and will also explore into using the co-clicks data to come up with simpler methods that can match the performance of more complex methods \cite{chen2018quora, chandra2020experiments, abishek2019enhanced, dadashovquora}.

%Once we have produced various training datasets we will explore how these datasets can be used for transfer learning. One task in this direction is to perform Query Synonym Prediction that is defined as a task that infers word synonyms from the co-clicks in the ORCAS dataset. These synonyms can then be used to identify similar queries efficiently.



%Previously the research community has extensively worked on the publicly available Quora Dupilcate Questions Dataset\footnote{https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs} released by the popular Question Answering platform themselves. Several works \cite{chen2018quora, chandra2020experiments, abishek2019enhanced , dadashovquora} on this dataset have used concepts such as feature engineering (feature extraction, term frequency-inverse document frequency (TF-IDF), word embeddings etc.) with Neural Network models (LSTM, RNN, CNN etc.) to identify the duplicate questions in this dataset. However these works make use of complex models for this task. To simplify this we believe that we can use the synonyms generated by our model as features on the Quora Duplicate Questions dataset and fine tune our pre-trained model to perform the same task of detecting the duplicate questions effectively using non-complex methods.

%Another interesting work HolisticOpt \cite{he2016automatic} aligns with our thought process as it makes use of query log clicks and web table attribute name co-occurrences to find attribute synonyms that can be used to boost the performance of search engines.

%We intend to use contextual and non contextual word representations to explore how these methods can represent n-gram and query similarity and build our own dataset containing the query synonyms that are generated. The evaluation can be both quantitative and qualitative where for quantitative analysis we will focus on predicting the degree of connection between queries (measured by proximity in click graph) and between n-gram terms. We will also compare our results with baseline methods such as using the Quora Duplicate Question dataset or evaluating the quality of our synonyms using the synonyms mined from English dictionaries such as Merriam-Webster dictionary. The qualitative evaluation for our task will include getting the generated query synonyms analyzed by human evaluators to check the quality.

\subsection{Query Rewriting}
Query rewriting is the process of automatically expanding a search query to better understand the user's intent. Query rewriting is typically used for improving the recall of IR systems, to retrieve a larger set of relevant results. We propose to use queries that have the same co-clicks in ORCAS as parallel data to train a sequence-to-sequence model to do query re-writing. Specifically, we intend to finetune a pre-trained encoder-decoder model \cite{lewis2020bart, raffel2020exploring} using these similar query pairs. Then, we plan to explore how our query re-writing approach can be used to improve established ranking models like BM25 \cite{robertson2009probabilistic} and neural IR models \cite{karpukhin2020dense, khattab2020colbert} on popular IR benchmarks like MS MARCO \cite{Campos2016MSMA}.

Another potential direction to explore is converting keyword based queries to natural language queries. Current neural network based IR systems, which are built for semantic search, might fall short against keyword-based queries. Hence, converting such queries into natural language would not just improve IR performance but also help understand searcher intent and query context, which are critical in query understanding. To achieve this, we plan to create parallel data from co-clicks, with smaller queries considered to be keyword-based and those with more words categorized as natural language queries. We will evaluate our approach using the TREC Web track\footnote{\href{https://trec.nist.gov/data/webmain.html}{https://trec.nist.gov/data/webmain.html}}, which contains both keyword-based and natural language questions with information seeking behaviors that are common in web search. 

%Similar to synonym detection, we will explore the effect of using our processed dataset on information retrieval centric domain. Using the MSMARCO baseline (other baselines?) we will explore how the use of our processed data can be applied to improve existing and established ranking models like BM25.  